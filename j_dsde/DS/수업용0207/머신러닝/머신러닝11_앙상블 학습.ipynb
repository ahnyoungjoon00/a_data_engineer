{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1193b1f3",
   "metadata": {},
   "source": [
    "# 앙상블 학습 (Ensemble Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836f91c",
   "metadata": {},
   "source": [
    "### 앙상블 학습을 통한 분류\n",
    "- 여러 개의 분류기(Classifier)를 사용해서 예측 결합\n",
    "\n",
    "    \n",
    "대표적인 앙상블 알고리즘\n",
    "- 랜덤 포레스트\n",
    "- 그레디언트 부스팅\n",
    "\n",
    "앙상블 알고리즘 변화\n",
    "- 부스팅 계열의 앙상블 알고리즘의 인기와 강세가 계속 이어짐\n",
    "\n",
    "최신 앙상블 알고리즘\n",
    "- XGBoost\n",
    "- LightGBM \n",
    "- Stacking  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265d7c5",
   "metadata": {},
   "source": [
    "#### 앙상블 학습 유형  \n",
    "- 보팅(Voting)  \n",
    "- 배깅(Bagging)  \n",
    "- 부스팅 (Boosting)  \n",
    "- 스태킹 등  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669877db",
   "metadata": {},
   "source": [
    "### 보팅(Voting) 과 배깅(Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd5bf0",
   "metadata": {},
   "source": [
    "보팅(Voting) : 여러 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식  \n",
    "    - **여러개의 서로 다른 알고리즘을 사용**   \n",
    "    - 데이터는 모든 불류기에 동일한 데이터를 사용\n",
    "배깅(Bagging) : 보팅과 동일하게 여러 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식  \n",
    "    - **여러개의 동일한 알고리즘을 사용**   \n",
    "    - 의사결정 트리 여러개를 사용해서 학습을 진행 >> 서로 다른 데이터셋을 사용해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6ae89",
   "metadata": {},
   "source": [
    "샘플링 방식 : 부트 스트래핑 분할 방식  \n",
    "- 개별 Classifier에게 데이터를 샘플링해서 추출하는 방식\n",
    "    - ex) (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    - dataset 1 (1, 3, 5, 7, 9, 10)\n",
    "    - dataset 2 (2, 4, 6, 8, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b13e3",
   "metadata": {},
   "source": [
    "#### 보팅 유형  \n",
    "- 하드 보팅 (Hard Voting)  \n",
    "- 소프트 보팅 (Soft Voting)  \n",
    "\n",
    "하드 보팅 (Hard Voting)  \n",
    "- 다수결 원칙과 유사  \n",
    "\n",
    "\n",
    "소프트 보팅 (Soft Voting)  \n",
    "- 분류기들이 레이블 값 결정 확률을 평균내서 확률이 가장 높은 레이블 값 선정\n",
    "- 성능이 좀더 좋다고 알려져있음\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bd669",
   "metadata": {},
   "source": [
    "### 부스팅 (Boosting)  \n",
    " \n",
    "- 머신러닝에서의 부스팅\n",
    "    - 약한 모델을 여러 번 순차적으로 적용해서 강한 모델로 만들어 간다는 의미\n",
    "\n",
    "\n",
    "    \n",
    "대표적인 부스팅 알고리즘 (패키지/모듈)   \n",
    "- Gradient Boost  \n",
    "- XGBoost(eXtra Gradient Boost)\n",
    "- LightGBM(Light Gradient Boost)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554479c",
   "metadata": {},
   "source": [
    "### 스태킹  (Statcking)  \n",
    "- 여러 가지 다른 모델의 예측 결과값으로 다시 학습 데이터로 만들어서  \n",
    "- 다른 모델(메타 모델)로 재학습시켜 결과를 예측하는 방식 : 예측 데이터를 이용한 재학습   \n",
    "- 기반 모델 + 메타 모델\n",
    "    - 기반 모델 : 1차 예측을 수행하는 개별 알고리즘\n",
    "    - 메타 모델 : 기반 모델의 예측 결과를 최종 데이터 세트로 학습하는 별도의 알고리즘\n",
    "- 현업 적용에는 무리가 있음\n",
    "    - 실데이터가 아닌 예측 데이터를 통한 예측\n",
    "    - 모델 경진대회에서도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940056f-10bf-4ba9-8d95-f545468051f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
