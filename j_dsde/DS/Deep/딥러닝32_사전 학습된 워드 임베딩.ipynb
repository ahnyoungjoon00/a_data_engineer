{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 학습된 워드 임베딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 학습된 워드 임베딩 벡터 사용 \n",
    "  - 자연어 처리 작업 시 학습 데이터로 직접 처음부터 임베딩 학습을 시키기도 하지만\n",
    "  - 위키피디아 등의 방대한 데이터로 이미 학습된 워드 임베딩(pre-trained word embedding vector)을 가져다 사용 가능\n",
    "- 예 : 감성 분석 작업 시 학습 데이터 양이 부족한 경우\n",
    "  - 이미 방대한 데이터로 Word2Vec이나 GloVe 등을 사용하여 사전에 학습시켜놓은 임베딩 벡터 가져와서\n",
    "  - 모델의 입력으로 사용 가능\n",
    "  - 더 좋은 성능을 얻을 수도 있음 \n",
    "- 구글에서 제공하는 사전 학습된 Word2Vec 모델 사용 방법\n",
    "  - 구글에서는 사전 힉습된 3백만 개의 Word2Vec 단어 벡터 제공\n",
    "  - 각 임베딩 벡터의 차원은 300 \n",
    "  - gensim을 통해서 이 모델 다운로드하고 파일 경로만 기재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스의 임베딩 층(embedding layer)과 사전 학습된 워드 임베딩(pre-trained word embedding)을 가져와서 사용하는 것 비교\n",
    "- 사전 훈련된 GloVe\n",
    "- 사전 훈련된 Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터가 적은 경우 최적화된 임베딩 벡터값을 구하는 것이 쉽지 않음\n",
    "- 그래서 많은 학습 데이터로 이미 학습 완료된 임베딩 벡터를 가져와서 사용하는 것이\n",
    "- 성능 개선을 가져올 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UEh3TIbQBnB"
   },
   "source": [
    "### (1) 케라스 임베딩 층(Keras Embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBEq_NokPhdN"
   },
   "source": [
    "- 임베딩층 구현하여 임베딩 벡터로 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0Zs1zoLEPkkv"
   },
   "outputs": [],
   "source": [
    "# 긍/부정 감성 데이터 \n",
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]\n",
    "# 긍정 : 1\n",
    "# 부정 : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPO7VSsNPlYu",
    "outputId": "c00fdc91-b835-4b68-8cda-97405147845a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_nGLh4jPn6G",
    "outputId": "4fbe017a-e054-4267-cca0-52699e7c5e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(seq) for seq in X_encoded)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ic5dberhPpQ-",
    "outputId": "904f031c-41f9-4e19-9ec5-6f6f1e11a3c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 패딩 \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "X_train = pad_sequences(X_encoded, maxlen=max_len,  padding='post')\n",
    "y_train = np.array(y_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 긍/부정 감성 분석 이진 분류 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_size = 텍스트 데이터의 전체 단어 집합 크기 (입력)  \n",
    "output_dim = 워드 임베딩 후의 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 벡터 크기 : 4\n",
    "# Embedding 층 \n",
    "# Flateen 층\n",
    "# Demse 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MUVmsvRYPqkG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - 767ms/step - accuracy: 0.5714 - loss: 0.6901\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 49ms/step - accuracy: 0.5714 - loss: 0.6884\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 0.5714 - loss: 0.6868\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.7143 - loss: 0.6851\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 0.7143 - loss: 0.6835\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.7143 - loss: 0.6818\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 46ms/step - accuracy: 0.7143 - loss: 0.6802\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.7143 - loss: 0.6785\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 0.7143 - loss: 0.6769\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 0.7143 - loss: 0.6752\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 0.8571 - loss: 0.6736\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.8571 - loss: 0.6719\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.8571 - loss: 0.6702\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 49ms/step - accuracy: 0.8571 - loss: 0.6686\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 0.8571 - loss: 0.6669\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 0.8571 - loss: 0.6652\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.6636\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.6619\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.6602\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.6585\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.6568\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.6551\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.6534\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6517\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6500\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.6482\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6465\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6448\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.6430\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6413\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6395\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.6377\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.6360\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6342\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.6324\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.6306\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 1.0000 - loss: 0.6288\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6270\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.6252\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.6234\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.6215\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6197\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.6179\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6160\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.6142\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.6123\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.6104\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.6086\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.6067\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.6048\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 47ms/step - accuracy: 1.0000 - loss: 0.6029\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 49ms/step - accuracy: 1.0000 - loss: 0.6010\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.5991\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 1.0000 - loss: 0.5972\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.5952\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 49ms/step - accuracy: 1.0000 - loss: 0.5933\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5914\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.5894\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5875\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.5855\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.5836\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 1.0000 - loss: 0.5816\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 1.0000 - loss: 0.5796\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 58ms/step - accuracy: 1.0000 - loss: 0.5776\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 53ms/step - accuracy: 1.0000 - loss: 0.5757\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 1.0000 - loss: 0.5737\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 1.0000 - loss: 0.5717\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5697\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.5676\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.5656\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5636\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5616\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5596\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5575\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5555\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5534\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5514\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5493\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5473\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 1.0000 - loss: 0.5452\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 66ms/step - accuracy: 1.0000 - loss: 0.5432\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5411\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.5390\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 1.0000 - loss: 0.5369\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5349\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5328\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 46ms/step - accuracy: 1.0000 - loss: 0.5307\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5286\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5265\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5244\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.5223\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5202\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5181\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.5160\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5139\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.5118\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5097\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.5075\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 1.0000 - loss: 0.5054\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.5033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x165e977cec0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "embedding_dim = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.5012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5011909604072571, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4uw-hLxP_m-"
   },
   "source": [
    "### (2) 사전 훈련된 GloVe 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "# urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"./data/glove.6B.zip\")\n",
    "# zf = zipfile.ZipFile('./data/glove.6B.zip', 'r')\n",
    "# zf.extractall('./data/') \n",
    "# zf.close()\n",
    "# zip 파일 압축제제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 앞에서 사용한 동일 데이터 사용\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMNEmTj0QZ2R",
    "outputId": "59af40a2-69e7-4b1b-96be-95b80058fbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector : 400000 개\n"
     ]
    }
   ],
   "source": [
    "# glove.6B.100d.txt에 있는 모든 임베딩 벡터 로드\n",
    "\n",
    "embedding_dict = dict()\n",
    "\n",
    "f = open('./data/0307/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "    word_vector_arr = np.array(word_vector[1:], dtype=\"float32\")\n",
    "    embedding_dict[word] = word_vector_arr\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print(f'Embedding vector : {len(embedding_dict)} 개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"nice great best amazing\", \"stop lies\", \"pitiful nerd\", \"excellent work\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.049773 ,  0.19903  ,  0.10585  ,  0.1391   , -0.32395  ,\n",
       "        0.44053  ,  0.3947   , -0.22805  , -0.25793  ,  0.49768  ,\n",
       "        0.15384  , -0.08831  ,  0.0782   , -0.8299   , -0.037788 ,\n",
       "        0.16772  , -0.45197  , -0.17085  ,  0.74756  ,  0.98256  ,\n",
       "        0.81872  ,  0.28507  ,  0.16178  , -0.48626  , -0.006265 ,\n",
       "       -0.92469  , -0.30625  , -0.067318 , -0.046762 , -0.76291  ,\n",
       "       -0.0025264, -0.018795 ,  0.12882  , -0.52457  ,  0.3586   ,\n",
       "        0.43119  , -0.89477  , -0.057421 , -0.53724  ,  0.25587  ,\n",
       "        0.55195  ,  0.44698  , -0.24252  ,  0.29946  ,  0.25776  ,\n",
       "       -0.8717   ,  0.68426  , -0.05688  , -0.1848   , -0.59352  ,\n",
       "       -0.11227  , -0.57692  , -0.013593 ,  0.18488  , -0.32507  ,\n",
       "       -0.90171  ,  0.17672  ,  0.075601 ,  0.54896  , -0.21488  ,\n",
       "       -0.54018  , -0.45882  , -0.79536  ,  0.26331  ,  0.18879  ,\n",
       "       -0.16363  ,  0.3975   ,  0.1099   ,  0.1164   , -0.083499 ,\n",
       "        0.50159  ,  0.35802  ,  0.25677  ,  0.088546 ,  0.42108  ,\n",
       "        0.28674  , -0.71285  , -0.82915  ,  0.15297  , -0.82712  ,\n",
       "        0.022112 ,  1.067    , -0.31776  ,  0.1211   , -0.069755 ,\n",
       "       -0.61327  ,  0.27308  , -0.42638  , -0.085084 , -0.17694  ,\n",
       "       -0.0090944,  0.1109   ,  0.62543  , -0.23682  , -0.44928  ,\n",
       "       -0.3667   , -0.21616  , -0.19187  , -0.032502 ,  0.38025  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 단어 'respectable'의 임베딩 벡터값 출력\n",
    "len(embedding_dict[\"respectable\"])\n",
    "embedding_dict[\"respectable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하고 있는 단어 집합 크기의 행과 100개의 열을 가지는 행렬 생성. 초기값으로 0으로 채움\n",
    "embedding_matrix = np.zeros((vocab_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embedding_matrix)\n",
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
     ]
    }
   ],
   "source": [
    "# 기존 데이터의 각 단어와 맵핑된 정수 인덱스 확인\n",
    "print(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nice': 1, 'great': 2, 'best': 3, 'amazing': 4, 'stop': 5, 'lies': 6, 'pitiful': 7, 'nerd': 8, 'excellent': 9, 'work': 10, 'supreme': 11, 'quality': 12, 'bad': 13, 'highly': 14, 'respectable': 15}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index[\"great\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nice': 1,\n",
       " 'great': 2,\n",
       " 'best': 3,\n",
       " 'amazing': 4,\n",
       " 'stop': 5,\n",
       " 'lies': 6,\n",
       " 'pitiful': 7,\n",
       " 'nerd': 8,\n",
       " 'excellent': 9,\n",
       " 'work': 10,\n",
       " 'supreme': 11,\n",
       " 'quality': 12,\n",
       " 'bad': 13,\n",
       " 'highly': 14,\n",
       " 'respectable': 15}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.013786 ,  0.38216  ,  0.53236  ,  0.15261  , -0.29694  ,\n",
       "       -0.20558  , -0.41846  , -0.58437  , -0.77355  , -0.87866  ,\n",
       "       -0.37858  , -0.18516  , -0.128    , -0.20584  , -0.22925  ,\n",
       "       -0.42599  ,  0.3725   ,  0.26077  , -1.0702   ,  0.62916  ,\n",
       "       -0.091469 ,  0.70348  , -0.4973   , -0.77691  ,  0.66045  ,\n",
       "        0.09465  , -0.44893  ,  0.018917 ,  0.33146  , -0.35022  ,\n",
       "       -0.35789  ,  0.030313 ,  0.22253  , -0.23236  , -0.19719  ,\n",
       "       -0.0053125, -0.25848  ,  0.58081  , -0.10705  , -0.17845  ,\n",
       "       -0.16206  ,  0.087086 ,  0.63029  , -0.76649  ,  0.51619  ,\n",
       "        0.14073  ,  1.019    , -0.43136  ,  0.46138  , -0.43585  ,\n",
       "       -0.47568  ,  0.19226  ,  0.36065  ,  0.78987  ,  0.088945 ,\n",
       "       -2.7814   , -0.15366  ,  0.01015  ,  1.1798   ,  0.15168  ,\n",
       "       -0.050112 ,  1.2626   , -0.77527  ,  0.36031  ,  0.95761  ,\n",
       "       -0.11385  ,  0.28035  , -0.02591  ,  0.31246  , -0.15424  ,\n",
       "        0.3778   , -0.13599  ,  0.2946   , -0.31579  ,  0.42943  ,\n",
       "        0.086969 ,  0.019169 , -0.27242  , -0.31696  ,  0.37327  ,\n",
       "        0.61997  ,  0.13889  ,  0.17188  ,  0.30363  , -1.2776   ,\n",
       "        0.044423 , -0.52736  , -0.88536  , -0.19428  , -0.61947  ,\n",
       "       -0.10146  , -0.26301  , -0.061707 ,  0.36627  , -0.95223  ,\n",
       "       -0.39346  , -0.69183  , -1.0426   ,  0.28855  ,  0.63056  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "embedding_dict[\"great\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 단어를 사전 학습된 GloVe의 임베딩 벡터값 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    vector_value = embedding_dict.get(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.013786  ,  0.38216001,  0.53236002,  0.15261   , -0.29694   ,\n",
       "       -0.20558   , -0.41846001, -0.58437002, -0.77354997, -0.87866002,\n",
       "       -0.37858   , -0.18516   , -0.12800001, -0.20584001, -0.22925   ,\n",
       "       -0.42598999,  0.3725    ,  0.26076999, -1.07019997,  0.62915999,\n",
       "       -0.091469  ,  0.70348001, -0.4973    , -0.77691001,  0.66044998,\n",
       "        0.09465   , -0.44893   ,  0.018917  ,  0.33146   , -0.35021999,\n",
       "       -0.35789001,  0.030313  ,  0.22253001, -0.23236001, -0.19719   ,\n",
       "       -0.0053125 , -0.25848001,  0.58081001, -0.10705   , -0.17845   ,\n",
       "       -0.16205999,  0.087086  ,  0.63028997, -0.76648998,  0.51618999,\n",
       "        0.14072999,  1.01900005, -0.43136001,  0.46138   , -0.43584999,\n",
       "       -0.47567999,  0.19226   ,  0.36065   ,  0.78987002,  0.088945  ,\n",
       "       -2.78139997, -0.15366   ,  0.01015   ,  1.17980003,  0.15167999,\n",
       "       -0.050112  ,  1.26259995, -0.77526999,  0.36030999,  0.95761001,\n",
       "       -0.11385   ,  0.28035   , -0.02591   ,  0.31246001, -0.15424   ,\n",
       "        0.37779999, -0.13598999,  0.29460001, -0.31579   ,  0.42943001,\n",
       "        0.086969  ,  0.019169  , -0.27241999, -0.31696001,  0.37327   ,\n",
       "        0.61997002,  0.13889   ,  0.17188001,  0.30362999, -1.27760005,\n",
       "        0.044423  , -0.52736002, -0.88536   , -0.19428   , -0.61947   ,\n",
       "       -0.10146   , -0.26301   , -0.061707  ,  0.36627001, -0.95222998,\n",
       "       -0.39346001, -0.69182998, -1.04260004,  0.28854999,  0.63055998])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[2]\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍/부정 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - 624ms/step - accuracy: 0.4286 - loss: 0.7505\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 0.4286 - loss: 0.7259\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.4286 - loss: 0.7021\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.4286 - loss: 0.6791\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 0.4286 - loss: 0.6569\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 47ms/step - accuracy: 0.4286 - loss: 0.6354\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.5714 - loss: 0.6147\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 44ms/step - accuracy: 0.7143 - loss: 0.5947\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.7143 - loss: 0.5754\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.7143 - loss: 0.5567\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.7143 - loss: 0.5387\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.7143 - loss: 0.5213\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.8571 - loss: 0.5046\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 0.8571 - loss: 0.4884\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.8571 - loss: 0.4727\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.8571 - loss: 0.4576\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.4430\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.4290\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.4154\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.4022\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.3895\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.3773\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.3655\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.3540\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.3430\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.3324\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.3221\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.3122\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.3026\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.2934\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.2845\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.2759\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.2676\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.2596\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 50ms/step - accuracy: 1.0000 - loss: 0.2519\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.2445\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.2373\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.2304\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.2237\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.2173\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.2111\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.2051\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1993\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.1937\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1883\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1831\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.1781\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1733\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1686\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.1641\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.1597\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.1555\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.1515\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1475\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1437\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1401\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1365\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 45ms/step - accuracy: 1.0000 - loss: 0.1331\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.1298\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.1265\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 1.0000 - loss: 0.1234\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.1204\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1175\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1147\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.1120\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.1094\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.1068\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.1043\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.1019\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0996\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0974\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0952\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0931\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.0910\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0890\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0871\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0852\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.0834\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0816\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.0799\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0783\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0767\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 72ms/step - accuracy: 1.0000 - loss: 0.0751\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0736\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0721\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 48ms/step - accuracy: 1.0000 - loss: 0.0706\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0692\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.0679\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.0666\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0653\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.0640\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 38ms/step - accuracy: 1.0000 - loss: 0.0628\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 1.0000 - loss: 0.0616\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.0605\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 86ms/step - accuracy: 1.0000 - loss: 0.0593\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.0582\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.0572\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0561\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0551\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x165fd0a6ba0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, output_dim = 100, weights=[embedding_matrix], trainable=True)) # trainable : 재학습 여부 T/F\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05318016931414604, 1.0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T1O4SrARZzI"
   },
   "source": [
    "### (3)사전 훈련된 Word2Vec 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OFhk9EtKRkVG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.4 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "word2ve_embedding_dict = gensim.models.KeyedVectors.load_word2vec_format('./data/0307/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x165fe3fd6d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2ve_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(word2ve_embedding_dict.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2ve_embedding_dict['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2ve_embedding_dict에서 특정 단어를 입력하면 해당 단어의 임베딩 벡터를 반환 받을 때\n",
    "# word2ve_embedding_dict에 특정 단어의 임베딩 벡터값이 없는 경우 None 값 반환하는 함수 \n",
    "def get_vector(word) :\n",
    "    if word in word2ve_embedding_dict :\n",
    "        return word2ve_embedding_dict[word]\n",
    "    else :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items() :\n",
    "    vector_value = get_vector(word)\n",
    "    if vector_value is not None :\n",
    "        embedding_matrix[index] = vector_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15820312,  0.10595703, -0.18945312,  0.38671875,  0.08349609,\n",
       "       -0.26757812,  0.08349609,  0.11328125, -0.10400391,  0.17871094,\n",
       "       -0.12353516, -0.22265625, -0.01806641, -0.25390625,  0.13183594,\n",
       "        0.0859375 ,  0.16113281,  0.11083984, -0.11083984, -0.0859375 ,\n",
       "        0.0267334 ,  0.34570312,  0.15136719, -0.00415039,  0.10498047,\n",
       "        0.04907227, -0.06982422,  0.08642578,  0.03198242, -0.02844238,\n",
       "       -0.15722656,  0.11865234,  0.36132812,  0.00173187,  0.05297852,\n",
       "       -0.234375  ,  0.11767578,  0.08642578, -0.01123047,  0.25976562,\n",
       "        0.28515625, -0.11669922,  0.38476562,  0.07275391,  0.01147461,\n",
       "        0.03466797,  0.18164062, -0.03955078,  0.04199219,  0.01013184,\n",
       "       -0.06054688,  0.09765625,  0.06689453,  0.14648438, -0.12011719,\n",
       "        0.08447266, -0.06152344,  0.06347656,  0.3046875 , -0.35546875,\n",
       "       -0.2890625 ,  0.19628906, -0.33203125, -0.07128906,  0.12792969,\n",
       "        0.09619141, -0.12158203, -0.08691406, -0.12890625,  0.27734375,\n",
       "        0.265625  ,  0.1796875 ,  0.12695312,  0.06298828, -0.34375   ,\n",
       "       -0.05908203,  0.0456543 ,  0.171875  ,  0.08935547,  0.14648438,\n",
       "       -0.04638672, -0.00842285, -0.0279541 ,  0.234375  , -0.07470703,\n",
       "       -0.13574219,  0.00378418,  0.19433594,  0.05664062, -0.05419922,\n",
       "        0.06176758,  0.14160156, -0.24121094,  0.02539062, -0.15917969,\n",
       "       -0.10595703,  0.11865234,  0.24707031, -0.13574219, -0.20410156,\n",
       "       -0.30078125,  0.07910156, -0.04394531,  0.02026367, -0.05786133,\n",
       "        0.2109375 ,  0.13574219,  0.08349609, -0.0098877 , -0.10546875,\n",
       "       -0.08105469,  0.03735352, -0.10351562, -0.10205078,  0.23925781,\n",
       "       -0.21875   ,  0.05151367,  0.06738281,  0.07617188,  0.04638672,\n",
       "        0.03198242, -0.07275391,  0.14550781,  0.04858398, -0.05664062,\n",
       "       -0.07470703, -0.0030365 , -0.09277344, -0.11083984, -0.03320312,\n",
       "       -0.15234375, -0.12207031,  0.09814453,  0.375     ,  0.00454712,\n",
       "       -0.10009766,  0.02734375,  0.30078125, -0.0390625 ,  0.30078125,\n",
       "       -0.04541016, -0.00424194,  0.13671875, -0.18945312, -0.21777344,\n",
       "        0.12695312, -0.02746582, -0.18164062,  0.08984375, -0.23339844,\n",
       "        0.203125  ,  0.2734375 , -0.26953125,  0.15332031, -0.20703125,\n",
       "       -0.01153564,  0.12451172,  0.05395508, -0.23535156, -0.01409912,\n",
       "       -0.09765625,  0.20800781,  0.19335938,  0.14746094,  0.28710938,\n",
       "       -0.23046875,  0.01965332, -0.09619141, -0.0703125 , -0.04174805,\n",
       "       -0.17578125,  0.0007019 ,  0.10546875,  0.10351562,  0.02478027,\n",
       "        0.35742188,  0.17382812, -0.09570312, -0.18359375,  0.23242188,\n",
       "       -0.14453125, -0.20410156, -0.01867676,  0.06640625, -0.2265625 ,\n",
       "       -0.00582886, -0.08642578,  0.02416992, -0.07324219, -0.29882812,\n",
       "       -0.15625   ,  0.07666016,  0.19628906, -0.20410156,  0.09863281,\n",
       "       -0.01672363, -0.18652344, -0.12353516, -0.16015625, -0.10058594,\n",
       "        0.21777344,  0.09375   , -0.10058594, -0.03637695,  0.15136719,\n",
       "       -0.02526855, -0.23730469,  0.03417969, -0.00604248,  0.15625   ,\n",
       "       -0.14257812,  0.18066406, -0.35351562,  0.25      ,  0.13085938,\n",
       "       -0.04296875,  0.17089844,  0.20507812,  0.00680542, -0.08251953,\n",
       "       -0.06738281,  0.22167969, -0.16308594, -0.16699219, -0.02087402,\n",
       "        0.11035156,  0.06054688, -0.04223633, -0.17285156,  0.05029297,\n",
       "       -0.19824219,  0.01495361,  0.06542969,  0.03271484,  0.14453125,\n",
       "       -0.08691406, -0.11035156, -0.1484375 ,  0.09667969,  0.22363281,\n",
       "        0.23535156,  0.08398438,  0.18164062, -0.10595703, -0.04296875,\n",
       "        0.11572266, -0.00153351,  0.0534668 , -0.1328125 , -0.33203125,\n",
       "       -0.08251953,  0.30664062,  0.22363281,  0.27929688,  0.09082031,\n",
       "       -0.18066406, -0.00613403, -0.09423828, -0.21289062,  0.01965332,\n",
       "       -0.08105469, -0.06689453, -0.31835938, -0.08447266,  0.13574219,\n",
       "        0.0625    ,  0.07080078, -0.14257812, -0.11279297,  0.01452637,\n",
       "       -0.06689453,  0.03881836,  0.19433594,  0.09521484,  0.11376953,\n",
       "       -0.12451172,  0.13769531, -0.18847656, -0.05224609,  0.15820312,\n",
       "        0.09863281, -0.04370117, -0.06054688,  0.21679688,  0.04077148,\n",
       "       -0.14648438, -0.18945312, -0.25195312, -0.16894531, -0.08642578,\n",
       "       -0.08544922,  0.18945312, -0.14648438,  0.13476562, -0.04077148,\n",
       "        0.03271484,  0.08935547, -0.26757812,  0.00836182, -0.21386719])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.836944580078125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]\n",
    "embedding_matrix[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15820312,  0.10595703, -0.18945312,  0.38671875,  0.08349609,\n",
       "       -0.26757812,  0.08349609,  0.11328125, -0.10400391,  0.17871094,\n",
       "       -0.12353516, -0.22265625, -0.01806641, -0.25390625,  0.13183594,\n",
       "        0.0859375 ,  0.16113281,  0.11083984, -0.11083984, -0.0859375 ,\n",
       "        0.0267334 ,  0.34570312,  0.15136719, -0.00415039,  0.10498047,\n",
       "        0.04907227, -0.06982422,  0.08642578,  0.03198242, -0.02844238,\n",
       "       -0.15722656,  0.11865234,  0.36132812,  0.00173187,  0.05297852,\n",
       "       -0.234375  ,  0.11767578,  0.08642578, -0.01123047,  0.25976562,\n",
       "        0.28515625, -0.11669922,  0.38476562,  0.07275391,  0.01147461,\n",
       "        0.03466797,  0.18164062, -0.03955078,  0.04199219,  0.01013184,\n",
       "       -0.06054688,  0.09765625,  0.06689453,  0.14648438, -0.12011719,\n",
       "        0.08447266, -0.06152344,  0.06347656,  0.3046875 , -0.35546875,\n",
       "       -0.2890625 ,  0.19628906, -0.33203125, -0.07128906,  0.12792969,\n",
       "        0.09619141, -0.12158203, -0.08691406, -0.12890625,  0.27734375,\n",
       "        0.265625  ,  0.1796875 ,  0.12695312,  0.06298828, -0.34375   ,\n",
       "       -0.05908203,  0.0456543 ,  0.171875  ,  0.08935547,  0.14648438,\n",
       "       -0.04638672, -0.00842285, -0.0279541 ,  0.234375  , -0.07470703,\n",
       "       -0.13574219,  0.00378418,  0.19433594,  0.05664062, -0.05419922,\n",
       "        0.06176758,  0.14160156, -0.24121094,  0.02539062, -0.15917969,\n",
       "       -0.10595703,  0.11865234,  0.24707031, -0.13574219, -0.20410156,\n",
       "       -0.30078125,  0.07910156, -0.04394531,  0.02026367, -0.05786133,\n",
       "        0.2109375 ,  0.13574219,  0.08349609, -0.0098877 , -0.10546875,\n",
       "       -0.08105469,  0.03735352, -0.10351562, -0.10205078,  0.23925781,\n",
       "       -0.21875   ,  0.05151367,  0.06738281,  0.07617188,  0.04638672,\n",
       "        0.03198242, -0.07275391,  0.14550781,  0.04858398, -0.05664062,\n",
       "       -0.07470703, -0.0030365 , -0.09277344, -0.11083984, -0.03320312,\n",
       "       -0.15234375, -0.12207031,  0.09814453,  0.375     ,  0.00454712,\n",
       "       -0.10009766,  0.02734375,  0.30078125, -0.0390625 ,  0.30078125,\n",
       "       -0.04541016, -0.00424194,  0.13671875, -0.18945312, -0.21777344,\n",
       "        0.12695312, -0.02746582, -0.18164062,  0.08984375, -0.23339844,\n",
       "        0.203125  ,  0.2734375 , -0.26953125,  0.15332031, -0.20703125,\n",
       "       -0.01153564,  0.12451172,  0.05395508, -0.23535156, -0.01409912,\n",
       "       -0.09765625,  0.20800781,  0.19335938,  0.14746094,  0.28710938,\n",
       "       -0.23046875,  0.01965332, -0.09619141, -0.0703125 , -0.04174805,\n",
       "       -0.17578125,  0.0007019 ,  0.10546875,  0.10351562,  0.02478027,\n",
       "        0.35742188,  0.17382812, -0.09570312, -0.18359375,  0.23242188,\n",
       "       -0.14453125, -0.20410156, -0.01867676,  0.06640625, -0.2265625 ,\n",
       "       -0.00582886, -0.08642578,  0.02416992, -0.07324219, -0.29882812,\n",
       "       -0.15625   ,  0.07666016,  0.19628906, -0.20410156,  0.09863281,\n",
       "       -0.01672363, -0.18652344, -0.12353516, -0.16015625, -0.10058594,\n",
       "        0.21777344,  0.09375   , -0.10058594, -0.03637695,  0.15136719,\n",
       "       -0.02526855, -0.23730469,  0.03417969, -0.00604248,  0.15625   ,\n",
       "       -0.14257812,  0.18066406, -0.35351562,  0.25      ,  0.13085938,\n",
       "       -0.04296875,  0.17089844,  0.20507812,  0.00680542, -0.08251953,\n",
       "       -0.06738281,  0.22167969, -0.16308594, -0.16699219, -0.02087402,\n",
       "        0.11035156,  0.06054688, -0.04223633, -0.17285156,  0.05029297,\n",
       "       -0.19824219,  0.01495361,  0.06542969,  0.03271484,  0.14453125,\n",
       "       -0.08691406, -0.11035156, -0.1484375 ,  0.09667969,  0.22363281,\n",
       "        0.23535156,  0.08398438,  0.18164062, -0.10595703, -0.04296875,\n",
       "        0.11572266, -0.00153351,  0.0534668 , -0.1328125 , -0.33203125,\n",
       "       -0.08251953,  0.30664062,  0.22363281,  0.27929688,  0.09082031,\n",
       "       -0.18066406, -0.00613403, -0.09423828, -0.21289062,  0.01965332,\n",
       "       -0.08105469, -0.06689453, -0.31835938, -0.08447266,  0.13574219,\n",
       "        0.0625    ,  0.07080078, -0.14257812, -0.11279297,  0.01452637,\n",
       "       -0.06689453,  0.03881836,  0.19433594,  0.09521484,  0.11376953,\n",
       "       -0.12451172,  0.13769531, -0.18847656, -0.05224609,  0.15820312,\n",
       "        0.09863281, -0.04370117, -0.06054688,  0.21679688,  0.04077148,\n",
       "       -0.14648438, -0.18945312, -0.25195312, -0.16894531, -0.08642578,\n",
       "       -0.08544922,  0.18945312, -0.14648438,  0.13476562, -0.04077148,\n",
       "        0.03271484,  0.08935547, -0.26757812,  0.00836182, -0.21386719],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.8369446"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2ve_embedding_dict[\"nice\"]\n",
    "word2ve_embedding_dict[\"nice\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n",
      "[1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding에 사전 학습된 embedding_matrix를 입력으로 넣어주고 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJmqMQ69RwfY",
    "outputId": "ba630b73-d8e7-4dde-ea9b-10d417154f91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - 849ms/step - acc: 0.5714 - loss: 0.6770\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 40ms/step - acc: 0.7143 - loss: 0.6587\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.6409\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.6237\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 47ms/step - acc: 1.0000 - loss: 0.6071\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 43ms/step - acc: 1.0000 - loss: 0.5909\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 44ms/step - acc: 1.0000 - loss: 0.5754\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 51ms/step - acc: 1.0000 - loss: 0.5603\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 39ms/step - acc: 1.0000 - loss: 0.5457\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.5317\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.5181\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 49ms/step - acc: 1.0000 - loss: 0.5050\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 45ms/step - acc: 1.0000 - loss: 0.4924\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 54ms/step - acc: 1.0000 - loss: 0.4802\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 48ms/step - acc: 1.0000 - loss: 0.4684\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.4571\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 39ms/step - acc: 1.0000 - loss: 0.4461\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.4355\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.4252\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 44ms/step - acc: 1.0000 - loss: 0.4153\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.4057\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.3964\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 42ms/step - acc: 1.0000 - loss: 0.3874\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 44ms/step - acc: 1.0000 - loss: 0.3787\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 43ms/step - acc: 1.0000 - loss: 0.3703\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 45ms/step - acc: 1.0000 - loss: 0.3621\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 45ms/step - acc: 1.0000 - loss: 0.3542\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.3465\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.3391\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.3319\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.3249\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.3181\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.3116\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 39ms/step - acc: 1.0000 - loss: 0.3052\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2990\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.2930\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.2871\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2814\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.2759\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.2706\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2654\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 34ms/step - acc: 1.0000 - loss: 0.2603\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.2554\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.2506\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2460\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.2414\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.2370\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2328\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.2286\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 34ms/step - acc: 1.0000 - loss: 0.2245\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 39ms/step - acc: 1.0000 - loss: 0.2206\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.2168\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.2130\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.2094\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.2058\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 51ms/step - acc: 1.0000 - loss: 0.2024\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 46ms/step - acc: 1.0000 - loss: 0.1990\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.1957\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.1925\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.1894\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.1863\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 89ms/step - acc: 1.0000 - loss: 0.1833\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 47ms/step - acc: 1.0000 - loss: 0.1804\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 48ms/step - acc: 1.0000 - loss: 0.1776\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 44ms/step - acc: 1.0000 - loss: 0.1748\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 42ms/step - acc: 1.0000 - loss: 0.1721\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.1695\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 41ms/step - acc: 1.0000 - loss: 0.1669\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1644\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.1620\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 40ms/step - acc: 1.0000 - loss: 0.1596\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1572\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.1549\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 42ms/step - acc: 1.0000 - loss: 0.1527\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.1505\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.1484\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.1463\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.1442\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1422\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.1402\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1383\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.1364\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1346\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1328\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 34ms/step - acc: 1.0000 - loss: 0.1310\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1293\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 34ms/step - acc: 1.0000 - loss: 0.1276\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.1260\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1244\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 46ms/step - acc: 1.0000 - loss: 0.1228\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.1212\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.1197\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 39ms/step - acc: 1.0000 - loss: 0.1182\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.1167\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1153\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 38ms/step - acc: 1.0000 - loss: 0.1139\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 35ms/step - acc: 1.0000 - loss: 0.1125\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1111\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 37ms/step - acc: 1.0000 - loss: 0.1098\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 36ms/step - acc: 1.0000 - loss: 0.1085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1658cef7140>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - acc: 1.0000 - loss: 0.1072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10720305144786835, 1.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 임베딩 벡터 생성 : loss 0.5\n",
    "# Glove 방식으로 기학습된 임베딩 벡터 사용 : loss 0.09\n",
    "# word2vec 방식으로 기학습된 임베딩 벡터 사용 : loss 0.1\n",
    "# 자연어 분석 진행 시, 기학습된 임베딩 벡터 사용하면 모델 성능이 좋아진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "사전 훈련된 임베딩.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DL_ENV",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
